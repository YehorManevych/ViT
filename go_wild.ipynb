{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook fine-tunes the replicated model up to 95% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.vision_transformer import ViT_B_16_Weights\n",
    "from torchvision.models.vision_transformer import vit_b_16\n",
    "import torch.backends.mps\n",
    "import math\n",
    "\n",
    "import data\n",
    "import eval\n",
    "import vit\n",
    "import train\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "\n",
    "def reload():\n",
    "    importlib.reload(data)\n",
    "    importlib.reload(eval)\n",
    "    importlib.reload(vit)\n",
    "    importlib.reload(train)\n",
    "    importlib.reload(utils)\n",
    "\n",
    "\n",
    "reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "device = utils.get_device()\n",
    "\n",
    "# ------------------Model architecture hyperparameters--------------------\n",
    "L = 12\n",
    "D = 768\n",
    "HEADS = 12\n",
    "PATCH = 16\n",
    "IMAGE_W = 224\n",
    "assert IMAGE_W % PATCH == 0, \"Image size must be divisible by the patch size\"\n",
    "N = int((IMAGE_W / PATCH) ** 2)\n",
    "assert D % HEADS == 0, \"The latent vector size D must be divisible by the number of heads\"\n",
    "# To keep num of params constant we set DH = D/HEADS\n",
    "DH = int(D / HEADS)\n",
    "DMSA = HEADS * DH * 3\n",
    "DMLP = 3072\n",
    "NORM_EPS = 1e-6\n",
    "\n",
    "# ---------------------Fine-tuning hyperparameters------------------------\n",
    "LR = 0.003\n",
    "MOMENTUM = 0.9\n",
    "STEPS = 10000\n",
    "BATCH = 32\n",
    "DROPOUT = 0.0\n",
    "\n",
    "# ----------------------------Other consts--------------------------------\n",
    "SEED = 100\n",
    "EVALS_PER_EPOCH = 1\n",
    "IMAGENET_CLASSES_N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading CIFAR-10 dataset\")\n",
    "train_ds, train_dl = data.load_CIFAR(\n",
    "    train=True, batch_size=BATCH, transforms=ViT_B_16_Weights.DEFAULT.transforms(), seed=SEED\n",
    ")\n",
    "test_ds, test_dl = data.load_CIFAR(\n",
    "    train=False, batch_size=BATCH, transforms=ViT_B_16_Weights.DEFAULT.transforms(), seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = math.ceil(STEPS * BATCH / len(train_ds))\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = test_ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.show(test_ds, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going wild with fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating the reference model\")\n",
    "weights = ViT_B_16_Weights.DEFAULT\n",
    "torch.manual_seed(SEED)\n",
    "ref_model = vit_b_16(weights=weights, dropout=DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Freezing the model and swapping it's classification head\")\n",
    "# freeze the ref model\n",
    "for p in ref_model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# swap the classification layer\n",
    "torch.manual_seed(SEED)\n",
    "lin = nn.Linear(in_features=D, out_features=len(classes))\n",
    "lin.weight = nn.Parameter(torch.zeros(len(classes), D))\n",
    "lin.bias = nn.Parameter(torch.zeros(len(classes)))\n",
    "ref_model.heads = nn.Sequential(lin).to(device)\n",
    "# summary(ref_model, depth=4, input_size=(1, 3, IMAGE_W, IMAGE_W),col_names=[\"kernel_size\", \"input_size\", \"output_size\", \"num_params\",\"trainable\"], row_settings=[\"var_names\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(ref_model.parameters(), lr=LR, momentum=MOMENTUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fine-tuning the reference model\")\n",
    "torch.manual_seed(SEED)\n",
    "train_metrics, test_metrics = train.train(\n",
    "    ref_model,\n",
    "    epochs,\n",
    "    train_dl,\n",
    "    test_dl,\n",
    "    device,\n",
    "    len(classes),\n",
    "    optim,\n",
    "    nn.CrossEntropyLoss(),\n",
    "    EVALS_PER_EPOCH,\n",
    "    checkpoints=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.plot_metrics(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.eval_show(ref_model, test_ds, n=16, page=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = test_metrics[eval.Metrics.ACCURACY.value][-1].item()\n",
    "utils.save_model(ref_model, accuracy, \"FT_CIFAR\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
