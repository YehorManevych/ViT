{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "from torchvision.models.vision_transformer import ViT_B_16_Weights\n",
    "from torchvision.models.vision_transformer import vit_b_16\n",
    "from pathlib import Path\n",
    "import torchvision.transforms\n",
    "import math\n",
    "import torch.backends.mps\n",
    "import plotly.graph_objects as go \n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import data\n",
    "import eval\n",
    "import vit\n",
    "import train\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 100\n",
    "BATCH = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenette2_path = Path(\"imagenette2\")\n",
    "imagenet_classes_path = Path('imagenet_class_index.json')\n",
    "data_path, classes = data.prepare_imagenette(imagenette2_path, imagenet_classes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path= data_path/'train'\n",
    "test_data_path= data_path/'test'\n",
    "train_ds, test_ds, train_dl, test_dl = data.load_imagenette(train_data_path, test_data_path, classes, BATCH, ViT_B_16_Weights.DEFAULT.transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 31\n",
    "torch.random.manual_seed(SEED)\n",
    "mean= np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "imgs, ls = next(iter(test_dl))\n",
    "print(test_ds.classes[ls[i]])\n",
    "torchvision.transforms.ToPILImage()(imgs[i])\n",
    "img_orig = (imgs[i] * std.reshape(3,1,1))+mean.reshape(3,1,1)\n",
    "torchvision.transforms.ToPILImage()(img_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval the ref model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ViT_B_16_Weights.DEFAULT\n",
    "ref_model = vit_b_16(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.eval(ref_model, test_dl, len(test_ds.classes), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval.eval_show(ref_model, test_ds, n=8, page=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 12\n",
    "D = 768\n",
    "HEADS = 12\n",
    "\n",
    "PATCH = 16\n",
    "IMAGE_W = 224\n",
    "assert IMAGE_W % PATCH == 0, \"Image size must be divisible by the patch size\"\n",
    "N = int((IMAGE_W/PATCH)**2)\n",
    "assert D % HEADS == 0, \"The latent vector size D must be divisible by the number of heads\"\n",
    "DH = int(D/HEADS) # To keep num of params constant we set DH = D/HEADS\n",
    "DMSA = HEADS*DH*3\n",
    "DMLP = 3072 # 4 times the D\n",
    "\n",
    "NORM_EPS = 1e-6\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = vit.ViT(D, IMAGE_W, PATCH, HEADS, DMLP, L, len(classes), DROPOUT, NORM_EPS)\n",
    "summary(m, depth=4, input_size=(1, 3, IMAGE_W, IMAGE_W),col_names=[\"kernel_size\", \"input_size\", \"output_size\", \"num_params\"], row_settings=[\"var_names\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = m.state_dict()\n",
    "keys = np.array(list(state.keys()))\n",
    "\n",
    "max_len = -1\n",
    "max_i = -1\n",
    "for i, k in enumerate(keys):\n",
    "    if(len(k) >= max_len):\n",
    "        max_len = len(k)\n",
    "        max_i = i\n",
    "\n",
    "rows = 10\n",
    "pad_end = math.ceil(len(keys)/rows)*rows - len(keys)\n",
    "keys = np.pad(keys, (0,pad_end), constant_values='')\n",
    "\n",
    "margin  = 4\n",
    "lines = np.stack(np.array_split(keys, int(len(keys)/rows))).T\n",
    "for l in lines:\n",
    "    print((' ' * margin).join([str(key).ljust(max_len) for key in l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_state = ViT_B_16_Weights.DEFAULT.get_state_dict(progress=True)\n",
    "\n",
    "state[\"class_token\"] = ref_state[\"class_token\"].squeeze()\n",
    "state[\"conv_proj.weight\"] = ref_state[\"conv_proj.weight\"]\n",
    "state[\"conv_proj.bias\"] = ref_state[\"conv_proj.bias\"]\n",
    "state[\"encoder.pos_embeddings\"] = ref_state[\"encoder.pos_embedding\"]\n",
    "for l in range(L):\n",
    "    state[f\"encoder.layers.{l}.ln_1.weight\"] = ref_state[f\"encoder.layers.encoder_layer_{l}.ln_1.weight\"]\n",
    "    state[f\"encoder.layers.{l}.ln_1.bias\"] = ref_state[f\"encoder.layers.encoder_layer_{l}.ln_1.bias\"]\n",
    "    state[f\"encoder.layers.{l}.msa.qkv\"] = ref_state[f\"encoder.layers.encoder_layer_{l}.self_attention.in_proj_weight\"]\n",
    "    state[f\"encoder.layers.{l}.msa.qkv_bias\"] = ref_state[f\"encoder.layers.encoder_layer_{l}.self_attention.in_proj_bias\"]\n",
    "    state[f\"encoder.layers.{l}.msa.w0\"] = ref_state[f\"encoder.layers.encoder_layer_{l}.self_attention.out_proj.weight\"]\n",
    "    state[f\"encoder.layers.{l}.msa.w0_bias\"] = ref_state[f\"encoder.layers.encoder_layer_{l}.self_attention.out_proj.bias\"]\n",
    "    state[f\"encoder.layers.{l}.ln_2.weight\"] = ref_state[f\"encoder.layers.encoder_layer_{l}.ln_2.weight\"]\n",
    "    state[f\"encoder.layers.{l}.ln_2.bias\"] = ref_state[f\"encoder.layers.encoder_layer_{l}.ln_2.bias\"]\n",
    "    state[f\"encoder.layers.{l}.mlp.lin1.weight\"] = ref_state[f\"encoder.layers.encoder_layer_{l}.mlp.linear_1.weight\"]\n",
    "    state[f\"encoder.layers.{l}.mlp.lin1.bias\"] = ref_state[f\"encoder.layers.encoder_layer_{l}.mlp.linear_1.bias\"]\n",
    "    state[f\"encoder.layers.{l}.mlp.lin2.weight\"] = ref_state[f\"encoder.layers.encoder_layer_{l}.mlp.linear_2.weight\"]\n",
    "    state[f\"encoder.layers.{l}.mlp.lin2.bias\"] = ref_state[f\"encoder.layers.encoder_layer_{l}.mlp.linear_2.bias\"]\n",
    "state[\"encoder.ln.weight\"] = ref_state[\"encoder.ln.weight\"]\n",
    "state[\"encoder.ln.bias\"] = ref_state[\"encoder.ln.bias\"]\n",
    "state[\"head.weight\"] = ref_state[\"heads.head.weight\"]\n",
    "state[\"head.bias\"] = ref_state[\"heads.head.bias\"]\n",
    "\n",
    "m.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.eval(m, test_dl, len(test_ds.classes), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval.eval_show(m, test_ds, 8, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Fine-tuning</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'eval' from '/Users/yehormanevych/Projects/ViT/eval.py'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)\n",
    "importlib.reload(data)\n",
    "importlib.reload(train)\n",
    "importlib.reload(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=32\n",
    "train_batch_n = 300\n",
    "test_batch_n = math.floor(train_batch_n*0.2/0.8)\n",
    "test_batch_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Created 261 train batches of size 32\n",
      "Files already downloaded and verified\n",
      "Created 63 test batches of size 32\n"
     ]
    }
   ],
   "source": [
    "cifar_train_ds, cifar_train_dl = data.load_cifar(\"cifar/train\", train=True, batch_size=batch_size, batch_n=train_batch_n, transforms=ViT_B_16_Weights.DEFAULT.transforms())\n",
    "cifar_test_ds, cifar_test_dl = data.load_cifar(\"cifar/test\", train=False, batch_size=batch_size, batch_n=test_batch_n, transforms=ViT_B_16_Weights.DEFAULT.transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_classes = cifar_test_ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# img, l = cifar_train_ds[i]\n",
    "# print(cifar_classes[l])\n",
    "# utils.whitened_to_PIL(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ViT_B_16_Weights.DEFAULT\n",
    "ref_model = vit_b_16(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze the ref model\n",
    "for p in ref_model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "#swap the classification layer\n",
    "ref_model.heads = nn.Sequential(nn.Linear(in_features=D, out_features=len(cifar_classes))).to(device)\n",
    "# summary(ref_model, depth=4, input_size=(1, 3, IMAGE_W, IMAGE_W),col_names=[\"kernel_size\", \"input_size\", \"output_size\", \"num_params\",\"trainable\"], row_settings=[\"var_names\"],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(ref_model.parameters(), lr=0.003, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "\tBatch 0\n",
      "\n",
      "\tTrain: MulticlassAccuracy = 0.062, MulticlassPrecision = 0.062, MulticlassRecall = 0.062, CrossEntropyLoss = 0.073\n",
      "\n",
      "\tTest: MulticlassAccuracy = 0.122, MulticlassPrecision = 0.119, MulticlassRecall = 0.122, CrossEntropyLoss = 0.073\n",
      "\tBatch 1\n",
      "\tBatch 2\n",
      "\tBatch 3\n",
      "\tBatch 4\n",
      "\tBatch 5\n",
      "\tBatch 6\n",
      "\tBatch 7\n",
      "\tBatch 8\n",
      "\tBatch 9\n",
      "\tBatch 10\n",
      "\tBatch 11\n",
      "\tBatch 12\n",
      "\tBatch 13\n",
      "\tBatch 14\n",
      "\tBatch 15\n",
      "\tBatch 16\n",
      "\tBatch 17\n",
      "\tBatch 18\n",
      "\tBatch 19\n",
      "\tBatch 20\n",
      "\tBatch 21\n",
      "\tBatch 22\n",
      "\tBatch 23\n",
      "\tBatch 24\n",
      "\tBatch 25\n",
      "\tBatch 26\n",
      "\tBatch 27\n",
      "\tBatch 28\n",
      "\tBatch 29\n",
      "\tBatch 30\n",
      "\tBatch 31\n",
      "\tBatch 32\n",
      "\tBatch 33\n",
      "\tBatch 34\n",
      "\tBatch 35\n",
      "\tBatch 36\n",
      "\tBatch 37\n",
      "\tBatch 38\n",
      "\tBatch 39\n",
      "\tBatch 40\n",
      "\tBatch 41\n",
      "\tBatch 42\n",
      "\tBatch 43\n",
      "\tBatch 44\n",
      "\tBatch 45\n",
      "\tBatch 46\n",
      "\tBatch 47\n",
      "\tBatch 48\n",
      "\tBatch 49\n",
      "\tBatch 50\n",
      "\tBatch 51\n",
      "\tBatch 52\n",
      "\tBatch 53\n",
      "\n",
      "\tTrain: MulticlassAccuracy = 0.782, MulticlassPrecision = 0.782, MulticlassRecall = 0.782, CrossEntropyLoss = 0.029\n",
      "\n",
      "\tTest: MulticlassAccuracy = 0.907, MulticlassPrecision = 0.907, MulticlassRecall = 0.907, CrossEntropyLoss = 0.012\n",
      "\tBatch 54\n",
      "\tBatch 55\n",
      "\tBatch 56\n",
      "\tBatch 57\n",
      "\tBatch 58\n",
      "\tBatch 59\n",
      "\tBatch 60\n",
      "\tBatch 61\n",
      "\tBatch 62\n",
      "\tBatch 63\n",
      "\tBatch 64\n",
      "\tBatch 65\n",
      "\tBatch 66\n",
      "\tBatch 67\n",
      "\tBatch 68\n",
      "\tBatch 69\n",
      "\tBatch 70\n",
      "\tBatch 71\n",
      "\tBatch 72\n",
      "\tBatch 73\n",
      "\tBatch 74\n",
      "\tBatch 75\n",
      "\tBatch 76\n",
      "\tBatch 77\n",
      "\tBatch 78\n",
      "\tBatch 79\n",
      "\tBatch 80\n",
      "\tBatch 81\n",
      "\tBatch 82\n",
      "\tBatch 83\n",
      "\tBatch 84\n",
      "\tBatch 85\n",
      "\tBatch 86\n",
      "\tBatch 87\n",
      "\tBatch 88\n",
      "\tBatch 89\n",
      "\tBatch 90\n",
      "\tBatch 91\n",
      "\tBatch 92\n",
      "\tBatch 93\n",
      "\tBatch 94\n",
      "\tBatch 95\n",
      "\tBatch 96\n",
      "\tBatch 97\n",
      "\tBatch 98\n",
      "\tBatch 99\n",
      "\tBatch 100\n",
      "\tBatch 101\n",
      "\tBatch 102\n",
      "\tBatch 103\n",
      "\tBatch 104\n",
      "\tBatch 105\n",
      "\tBatch 106\n",
      "\n",
      "\tTrain: MulticlassAccuracy = 0.908, MulticlassPrecision = 0.908, MulticlassRecall = 0.908, CrossEntropyLoss = 0.011\n",
      "\n",
      "\tTest: MulticlassAccuracy = 0.919, MulticlassPrecision = 0.920, MulticlassRecall = 0.919, CrossEntropyLoss = 0.010\n",
      "\tBatch 107\n",
      "\tBatch 108\n",
      "\tBatch 109\n",
      "\tBatch 110\n",
      "\tBatch 111\n",
      "\tBatch 112\n",
      "\tBatch 113\n",
      "\tBatch 114\n",
      "\tBatch 115\n",
      "\tBatch 116\n",
      "\tBatch 117\n",
      "\tBatch 118\n",
      "\tBatch 119\n",
      "\tBatch 120\n",
      "\tBatch 121\n",
      "\tBatch 122\n",
      "\tBatch 123\n",
      "\tBatch 124\n",
      "\tBatch 125\n",
      "\tBatch 126\n",
      "\tBatch 127\n",
      "\tBatch 128\n",
      "\tBatch 129\n",
      "\tBatch 130\n",
      "\tBatch 131\n",
      "\tBatch 132\n",
      "\tBatch 133\n",
      "\tBatch 134\n",
      "\tBatch 135\n",
      "\tBatch 136\n",
      "\tBatch 137\n",
      "\tBatch 138\n",
      "\tBatch 139\n",
      "\tBatch 140\n",
      "\tBatch 141\n",
      "\tBatch 142\n",
      "\tBatch 143\n",
      "\tBatch 144\n",
      "\tBatch 145\n",
      "\tBatch 146\n",
      "\tBatch 147\n",
      "\tBatch 148\n",
      "\tBatch 149\n",
      "\tBatch 150\n",
      "\tBatch 151\n",
      "\tBatch 152\n",
      "\tBatch 153\n",
      "\tBatch 154\n",
      "\tBatch 155\n",
      "\tBatch 156\n",
      "\tBatch 157\n",
      "\tBatch 158\n",
      "\tBatch 159\n",
      "\n",
      "\tTrain: MulticlassAccuracy = 0.912, MulticlassPrecision = 0.912, MulticlassRecall = 0.912, CrossEntropyLoss = 0.009\n",
      "\n",
      "\tTest: MulticlassAccuracy = 0.919, MulticlassPrecision = 0.919, MulticlassRecall = 0.919, CrossEntropyLoss = 0.009\n",
      "\tBatch 160\n",
      "\tBatch 161\n",
      "\tBatch 162\n",
      "\tBatch 163\n",
      "\tBatch 164\n",
      "\tBatch 165\n",
      "\tBatch 166\n",
      "\tBatch 167\n",
      "\tBatch 168\n",
      "\tBatch 169\n",
      "\tBatch 170\n",
      "\tBatch 171\n",
      "\tBatch 172\n",
      "\tBatch 173\n",
      "\tBatch 174\n",
      "\tBatch 175\n",
      "\tBatch 176\n",
      "\tBatch 177\n",
      "\tBatch 178\n",
      "\tBatch 179\n",
      "\tBatch 180\n",
      "\tBatch 181\n",
      "\tBatch 182\n",
      "\tBatch 183\n",
      "\tBatch 184\n",
      "\tBatch 185\n",
      "\tBatch 186\n",
      "\tBatch 187\n",
      "\tBatch 188\n",
      "\tBatch 189\n",
      "\tBatch 190\n",
      "\tBatch 191\n",
      "\tBatch 192\n",
      "\tBatch 193\n",
      "\tBatch 194\n",
      "\tBatch 195\n",
      "\tBatch 196\n",
      "\tBatch 197\n",
      "\tBatch 198\n",
      "\tBatch 199\n",
      "\tBatch 200\n",
      "\tBatch 201\n",
      "\tBatch 202\n",
      "\tBatch 203\n",
      "\tBatch 204\n",
      "\tBatch 205\n",
      "\tBatch 206\n",
      "\tBatch 207\n",
      "\tBatch 208\n",
      "\tBatch 209\n",
      "\tBatch 210\n",
      "\tBatch 211\n",
      "\tBatch 212\n",
      "\n",
      "\tTrain: MulticlassAccuracy = 0.938, MulticlassPrecision = 0.938, MulticlassRecall = 0.938, CrossEntropyLoss = 0.008\n",
      "\n",
      "\tTest: MulticlassAccuracy = 0.927, MulticlassPrecision = 0.926, MulticlassRecall = 0.927, CrossEntropyLoss = 0.008\n",
      "\tBatch 213\n",
      "\tBatch 214\n",
      "\tBatch 215\n",
      "\tBatch 216\n",
      "\tBatch 217\n",
      "\tBatch 218\n",
      "\tBatch 219\n",
      "\tBatch 220\n",
      "\tBatch 221\n",
      "\tBatch 222\n",
      "\tBatch 223\n",
      "\tBatch 224\n",
      "\tBatch 225\n",
      "\tBatch 226\n",
      "\tBatch 227\n",
      "\tBatch 228\n",
      "\tBatch 229\n",
      "\tBatch 230\n",
      "\tBatch 231\n",
      "\tBatch 232\n",
      "\tBatch 233\n",
      "\tBatch 234\n",
      "\tBatch 235\n",
      "\tBatch 236\n",
      "\tBatch 237\n",
      "\tBatch 238\n",
      "\tBatch 239\n",
      "\tBatch 240\n",
      "\tBatch 241\n",
      "\tBatch 242\n",
      "\tBatch 243\n",
      "\tBatch 244\n",
      "\tBatch 245\n",
      "\tBatch 246\n",
      "\tBatch 247\n",
      "\tBatch 248\n",
      "\tBatch 249\n",
      "\tBatch 250\n",
      "\tBatch 251\n",
      "\tBatch 252\n",
      "\tBatch 253\n",
      "\tBatch 254\n",
      "\tBatch 255\n",
      "\tBatch 256\n",
      "\tBatch 257\n",
      "\tBatch 258\n",
      "\tBatch 259\n",
      "\tBatch 260\n",
      "\n",
      "\tTrain: MulticlassAccuracy = 0.931, MulticlassPrecision = 0.931, MulticlassRecall = 0.931, CrossEntropyLoss = 0.007\n",
      "\n",
      "\tTest: MulticlassAccuracy = 0.926, MulticlassPrecision = 0.926, MulticlassRecall = 0.926, CrossEntropyLoss = 0.008\n"
     ]
    }
   ],
   "source": [
    "train_metrics, test_metrics = train.train(ref_model, 1, cifar_train_dl, cifar_test_dl, device, len(cifar_classes), optim, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_acc = [m[\"MulticlassAccuracy\"].cpu() for m in train_metrics]\n",
    "# train_loss = [m[\"CrossEntropyLoss\"].cpu() for m in train_metrics]\n",
    "# test_acc = [m[\"MulticlassAccuracy\"].cpu() for m in test_metrics]\n",
    "# test_loss = [m[\"CrossEntropyLoss\"].cpu() for m in test_metrics]\n",
    "\n",
    "# fig = make_subplots(cols=2, rows=1, subplot_titles=[\"Loss\", \"Accuracy\"])\n",
    "# fig.add_scatter(x = np.arange(len(train_loss)), y=train_loss, col=1, row=1, name=\"Train loss\")\n",
    "# fig.add_scatter(x = np.arange(len(train_acc)), y=train_acc, col=2, row=1, name=\"Train acc\")\n",
    "# fig.add_scatter(x = np.arange(len(test_loss)), y=test_loss, col=1, row=1, name=\"Test loss\")\n",
    "# fig.add_scatter(x = np.arange(len(test_acc)), y=test_acc, col=2, row=1, name=\"Test acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = Path(\"models\")\n",
    "models_path.mkdir(exist_ok=True)\n",
    "model_path = models_path / \"ref_model_b32_93acc.pth\"\n",
    "torch.save(ref_model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval.eval_show(ref_model.cpu(), cifar_test_ds, n=8, page=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
